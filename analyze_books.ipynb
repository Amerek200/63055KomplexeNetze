{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a28680df2df1ec9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T13:23:38.375756Z",
     "start_time": "2025-06-18T13:23:38.341074Z"
    }
   },
   "source": [
    "from importlib import reload\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import nx_parallel as nxp\n",
    "import scipy\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Importieren und neu laden (damit aktuelle Änderungen übernommen werden)\n",
    "from helper import graph_analyzer, file_preprocesser\n",
    "reload(file_preprocesser)\n",
    "reload(graph_analyzer)\n",
    "\n",
    "\n",
    "from helper.file_preprocesser import prepare_text, prepare_text_with_libraries, convert_preprocessed_tokens_to_graph, extract_metadata_from_file_name\n",
    "from helper.graph_analyzer import parallel_get_distance_measures, parallel_get_betweenness_list, get_powerlaw_result\n",
    "import config"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "id": "9e89293a435834c1",
   "metadata": {},
   "source": "### Optionen laden"
  },
  {
   "cell_type": "code",
   "id": "c3e5119ec4e7a27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T13:23:38.449963Z",
     "start_time": "2025-06-18T13:23:38.445232Z"
    }
   },
   "source": [
    "# Auslagern in config?\n",
    "nx.config.backends.parallel.active = config.ACTIVE_PARALLEL\n",
    "nx.config.backends.parallel.n_jobs = config.N_JOBS"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetworkXConfig(backend_priority=BackendPriorities(algos=[], generators=[]), backends=Config(parallel=ParallelConfig(active=True, backend='loky', n_jobs=4, verbose=0, temp_folder=None, max_nbytes='1M', mmap_mode='r', prefer=None, require=None, inner_max_num_threads=None, backend_params={})), cache_converted_graphs=True, fallback_to_nx=False, warnings_to_ignore=set())\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "id": "5d747da102a04f1f",
   "metadata": {},
   "source": [
    "### Dateipfade laden"
   ]
  },
  {
   "cell_type": "code",
   "id": "8cb24543676e765c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T13:23:38.512624Z",
     "start_time": "2025-06-18T13:23:38.489921Z"
    }
   },
   "source": [
    "# Liste mit Dateinamen von Büchern\n",
    "file_name_list = [f for f in listdir(config.DATA_PATH) if isfile(join(config.DATA_PATH, f))]\n",
    "\n",
    "# Liste mit Inhalten von Dateien\n",
    "file_content_list = [\" \".join(open(join(config.DATA_PATH, f)).readlines()) for f in file_name_list]\n"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "id": "4e806c9cb334c645",
   "metadata": {},
   "source": [
    "### Dataframe mit Dateinamen und Inhalt befüllen"
   ]
  },
  {
   "cell_type": "code",
   "id": "a042c30999b50a3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T13:23:38.581127Z",
     "start_time": "2025-06-18T13:23:38.527436Z"
    }
   },
   "source": [
    "# Tabelle erstellen mit Spalten \"title\" und \"content\"\n",
    "df = pd.DataFrame({'file_name': file_name_list, 'file_content': file_content_list})\n",
    "\n",
    "file_metadata = df[\"file_name\"].apply(extract_metadata_from_file_name).apply(pd.Series)\n",
    "\n",
    "df[[\"author\", \"title\", \"language\"]] = file_metadata\n",
    "\n",
    "print(df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  file_name  \\\n",
      "0      Kafka_Amerika_de.txt   \n",
      "1      Kafka_Prozess_en.txt   \n",
      "2      Kafka_Schloss_de.txt   \n",
      "3  Kafka_Verwandlung_de.txt   \n",
      "4            ALL_ALL_DE.txt   \n",
      "5      Kafka_Schloss_en.txt   \n",
      "6  Kafka_Verwandlung_en.txt   \n",
      "7      Kafka_Prozess_de.txt   \n",
      "8      Kafka_Amerika_en.txt   \n",
      "\n",
      "                                        file_content author        title  \\\n",
      "0  Der Heizer\\n Als der sechzehnjährige Karl Roßm...  Kafka      Amerika   \n",
      "1  Chapter One\\n \\n Arrest--Conversation with Mrs...  Kafka      Prozess   \n",
      "2  Es war spätabends, als K. ankam. Das Dorf lag ...  Kafka      Schloss   \n",
      "3  Als Gregor Samsa eines Morgens aus unruhigen T...  Kafka  Verwandlung   \n",
      "4  IN THE BEGINNING was the myth. God, in his sea...    ALL          ALL   \n",
      "5  1\\n Arrival\\n It was late evening when K. arri...  Kafka      Schloss   \n",
      "6  One morning, when Gregor Samsa woke from troub...  Kafka  Verwandlung   \n",
      "7  ERSTES KAPITEL\\n \\n VERHAFTUNG · GESPRÄCH MIT ...  Kafka      Prozess   \n",
      "8  THE STOKER\\n As the seventeen-year-old Karl Ro...  Kafka      Amerika   \n",
      "\n",
      "  language  \n",
      "0       de  \n",
      "1       en  \n",
      "2       de  \n",
      "3       de  \n",
      "4       DE  \n",
      "5       en  \n",
      "6       en  \n",
      "7       de  \n",
      "8       en  \n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "id": "acd741ebfb26e80a",
   "metadata": {},
   "source": [
    "### Text vorbereiten und Graphen erstellen"
   ]
  },
  {
   "cell_type": "code",
   "id": "f17fae84e6747569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T13:23:40.324262Z",
     "start_time": "2025-06-18T13:23:38.617581Z"
    }
   },
   "source": [
    "df[\"prepared_text\"] = df[\"file_content\"].apply(lambda text: prepare_text_with_libraries(text, remove_stopwords=config.REMOVE_STOPWORDS))\n",
    "df[\"stopwords_removed\"] = config.REMOVE_STOPWORDS\n",
    "df[\"link_distance\"] = config.LINK_DISTANCE\n",
    "df[\"graph\"] = df[\"prepared_text\"].apply(lambda g: convert_preprocessed_tokens_to_graph(g, config.LINK_DISTANCE))"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "id": "6ff579f7c571b267",
   "metadata": {},
   "source": [
    "### Metriken berechnen"
   ]
  },
  {
   "cell_type": "code",
   "id": "21e315e88630fd7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T13:23:40.351543Z",
     "start_time": "2025-06-18T13:23:40.341441Z"
    }
   },
   "source": [
    "# Basismetriken: Knotenanzahl und Kantenanzahl\n",
    "df[\"node_count\"] = df[\"graph\"].apply(lambda g: len(g.nodes))\n",
    "df[\"edge_count\"] = df[\"graph\"].apply(lambda g: len(g.edges))\n",
    "\n",
    "# Knotengrade\n",
    "df[\"degree_list\"] = df[\"graph\"].apply(lambda g: np.array([deg for node, deg in g.degree ]))\n",
    "# Alternative von ChatGPT: dataframe[\"degree_list\"] = dataframe[\"graph\"].apply(lambda g: np.fromiter(dict(g.degree).values(), dtype=float))\n",
    "df[\"average_degree\"] = df[\"degree_list\"].apply(lambda degree_list: np.mean(degree_list))\n",
    "df[\"median_degree\"] = df[\"degree_list\"].apply(lambda degree_list: np.median(degree_list))\n",
    "\n",
    "# Falls eingeschaltet: Parallele Berechnungen\n",
    "if PARALLEL:\n",
    "    distance_measures = df[\"graph\"].apply(parallel_get_distance_measures).apply(pd.Series)\n",
    "    df[[\"diameter\", \"average_distance\"]] = distance_measures\n",
    "    df[\"betweenness_list\"] = df[\"graph\"].apply(parallel_get_betweenness_list)\n",
    "\n",
    "# Ansonsten (NICHT parallel)\n",
    "else:\n",
    "    df[\"diameter\"] = df[\"graph\"].apply(lambda g: nx.diameter(g))\n",
    "    df[\"average_distance\"] = df[\"graph\"].apply(lambda g: nx.average_shortest_path_length(g))\n",
    "    df[\"betweenness_list\"] = df[\"graph\"].apply(lambda g : np.array( list(nx.betweenness_centrality(g).values()) ))\n",
    "\n",
    "# powerlaw-Eigenschaften bestimmen\n",
    "powerlaw_result = df[\"degree_list\"].apply(get_powerlaw_result).apply(pd.Series)\n",
    "df[[\"powerlaw_alpha_value\", \"powerlaw_xmin_value\"]] = powerlaw_result\n",
    "\n",
    "# Betweenness aus Liste der Einzelwerte\n",
    "df[\"betweenness_min\"] = df[\"betweenness_list\"].apply(np.min)\n",
    "df[\"betweenness_max\"] = df[\"betweenness_list\"].apply(np.max)\n",
    "df[\"betweenness_average\"] = df[\"betweenness_list\"].apply(np.mean)\n",
    "df[\"betweenness_standard_deviation\"] = df[\"betweenness_list\"].apply(np.std)\n",
    "\n",
    "\n",
    "# Clustering\n",
    "df[\"average_clustering\"] = df[\"graph\"].apply(lambda g: nx.average_clustering(g))\n"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "id": "9d6abf47b0fde5b8",
   "metadata": {},
   "source": [
    "### Speichern der Tabelle in Datei"
   ]
  },
  {
   "cell_type": "code",
   "id": "31b3b4be4d2fb7f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T13:23:40.387308Z",
     "start_time": "2025-06-18T13:23:40.369333Z"
    }
   },
   "source": [
    "# Nur bestimmte Spalten sollen in Datei geschrieben werden\n",
    "df[config.ATTRIBUTES_VISIBLE_IN_FILE].to_csv(\"data/output/output.csv\", index=False)\n",
    "\n",
    "print(df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  file_name  \\\n",
      "0      Kafka_Amerika_de.txt   \n",
      "1      Kafka_Prozess_en.txt   \n",
      "2      Kafka_Schloss_de.txt   \n",
      "3  Kafka_Verwandlung_de.txt   \n",
      "4            ALL_ALL_DE.txt   \n",
      "5      Kafka_Schloss_en.txt   \n",
      "6  Kafka_Verwandlung_en.txt   \n",
      "7      Kafka_Prozess_de.txt   \n",
      "8      Kafka_Amerika_en.txt   \n",
      "\n",
      "                                        file_content author        title  \\\n",
      "0  Der Heizer\\n Als der sechzehnjährige Karl Roßm...  Kafka      Amerika   \n",
      "1  Chapter One\\n \\n Arrest--Conversation with Mrs...  Kafka      Prozess   \n",
      "2  Es war spätabends, als K. ankam. Das Dorf lag ...  Kafka      Schloss   \n",
      "3  Als Gregor Samsa eines Morgens aus unruhigen T...  Kafka  Verwandlung   \n",
      "4  IN THE BEGINNING was the myth. God, in his sea...    ALL          ALL   \n",
      "5  1\\n Arrival\\n It was late evening when K. arri...  Kafka      Schloss   \n",
      "6  One morning, when Gregor Samsa woke from troub...  Kafka  Verwandlung   \n",
      "7  ERSTES KAPITEL\\n \\n VERHAFTUNG · GESPRÄCH MIT ...  Kafka      Prozess   \n",
      "8  THE STOKER\\n As the seventeen-year-old Karl Ro...  Kafka      Amerika   \n",
      "\n",
      "  language                                      prepared_text  \\\n",
      "0       de  [der, Heizer, als, der, sechzehnjährig, Karl, ...   \n",
      "1       en  [Chapter, One, Arrest, Conversation, with, Mrs...   \n",
      "2       de  [es, sein, Spätabend, als, ankommen, der, Dorf...   \n",
      "3       de  [als, Gregor, Samsa, ein, Morgen, aus, unruhig...   \n",
      "4       DE  [in, THE, BEGINNING, was, the, myth, God, in, ...   \n",
      "5       en  [Arrival, It, was, Late, evening, when, arrive...   \n",
      "6       en  [One, morning, when, Gregor, Samsa, woke, From...   \n",
      "7       de  [erster, KAPITEL, VERHAFTUNG, GESPRÄCH, mit, F...   \n",
      "8       en  [THE, STOKER, As, the, Karl, Rossmann, Who, ha...   \n",
      "\n",
      "   stopwords_removed  link_distance  \\\n",
      "0              False              1   \n",
      "1              False              1   \n",
      "2              False              1   \n",
      "3              False              1   \n",
      "4              False              1   \n",
      "5              False              1   \n",
      "6              False              1   \n",
      "7              False              1   \n",
      "8              False              1   \n",
      "\n",
      "                                               graph  node_count  edge_count  \n",
      "0  (der, Heizer, als, sechzehnjährig, Karl, Roßma...        7108       42468  \n",
      "1  (Chapter, One, Arrest, Conversation, with, Mrs...        4782       36013  \n",
      "2  (es, sein, Spätabend, als, ankommen, der, Dorf...        7086       47794  \n",
      "3  (als, Gregor, Samsa, ein, Morgen, aus, unruhig...        2854       11742  \n",
      "4  (in, THE, BEGINNING, was, the, myth, God, His,...        2167        5229  \n",
      "5  (Arrival, It, was, Late, evening, when, arrive...        6369       51413  \n",
      "6  (One, morning, when, Gregor, Samsa, woke, From...        2601       12759  \n",
      "7  (erster, KAPITEL, VERHAFTUNG, GESPRÄCH, mit, F...        5508       33476  \n",
      "8  (THE, STOKER, As, the, Karl, Rossmann, Who, ha...        7006       44849  \n"
     ]
    }
   ],
   "execution_count": 55
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (komplNetzeEnv",
   "language": "python",
   "name": "jupyterkomplnetze"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
