{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a28680df2df1ec9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T18:12:20.151148Z",
     "start_time": "2025-06-10T18:12:16.994989Z"
    }
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import nx_parallel as nxp\n",
    "import scipy\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Importieren und neu laden (damit aktuelle Änderungen übernommen werden)\n",
    "from helper import graph_analyzer, text_preprocesser\n",
    "reload(text_preprocesser)\n",
    "reload(graph_analyzer)\n",
    "\n",
    "\n",
    "from helper.text_preprocesser import prepare_text, prepare_text_with_libraries, convert_preprocessed_tokens_to_graph\n",
    "from helper.graph_analyzer import parallel_get_distance_measures, parallel_get_betweenness_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e89293a435834c1",
   "metadata": {},
   "source": [
    "### Optionen setzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3e5119ec4e7a27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T18:12:20.180583Z",
     "start_time": "2025-06-10T18:12:20.176644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetworkXConfig(backend_priority=BackendPriorities(algos=[], generators=[]), backends=Config(parallel=ParallelConfig(active=True, backend='loky', n_jobs=4, verbose=0, temp_folder=None, max_nbytes='1M', mmap_mode='r', prefer=None, require=None, inner_max_num_threads=None, backend_params={})), cache_converted_graphs=True, fallback_to_nx=False, warnings_to_ignore=set())\n"
     ]
    }
   ],
   "source": [
    "PARALLEL = False\n",
    "nx.config.backends.parallel.active = True\n",
    "nx.config.backends.parallel.n_jobs = 4\n",
    "print(nx.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d747da102a04f1f",
   "metadata": {},
   "source": [
    "### Dateipfade laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb24543676e765c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T18:12:20.482332Z",
     "start_time": "2025-06-10T18:12:20.478764Z"
    }
   },
   "outputs": [],
   "source": [
    "# Allgemeiner Pfad zu den Daten\n",
    "DATA_PATH = \"data/input/\"\n",
    "\n",
    "# Liste mit Dateinamen von Büchern\n",
    "file_name_list = [f for f in listdir(DATA_PATH) if isfile(join(DATA_PATH, f))]\n",
    "\n",
    "# Liste mit Inhalten von Dateien\n",
    "file_content_list = [\" \".join(open(join(DATA_PATH, f)).readlines()) for f in file_name_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e806c9cb334c645",
   "metadata": {},
   "source": [
    "### Dataframe mit Dateinamen und Inhalt befüllen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a042c30999b50a3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T18:12:20.507470Z",
     "start_time": "2025-06-10T18:12:20.497155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        file_name  \\\n",
      "0  Hesse_Camenzind_en_cleaned.txt   \n",
      "1                  ALL_ALL_DE.txt   \n",
      "2  Hesse_Camenzind_de_cleaned.txt   \n",
      "\n",
      "                                        file_content author      title  \\\n",
      "0  IN THE BEGINNING was the myth. God, in his sea...  Hesse  Camenzind   \n",
      "1  IN THE BEGINNING was the myth. God, in his sea...    ALL        ALL   \n",
      "2  Im Anfang war der Mythus. Wie der große Gott i...  Hesse  Camenzind   \n",
      "\n",
      "  language  \n",
      "0       en  \n",
      "1       DE  \n",
      "2       de  \n"
     ]
    }
   ],
   "source": [
    "# Tabelle erstellen mit Spalten \"title\" und \"content\"\n",
    "df = pd.DataFrame({'file_name': file_name_list, 'file_content': file_content_list})\n",
    "\n",
    "\n",
    "def extract_metadata_from_file_name(file_name):\n",
    "    splitted_name = file_name[:-4].split(\"_\")\n",
    "    author = splitted_name[0]\n",
    "    title = splitted_name[1]\n",
    "    language = splitted_name[2]\n",
    "    return author, title, language\n",
    "\n",
    "file_metadata = df[\"file_name\"].apply(extract_metadata_from_file_name).apply(pd.Series)\n",
    "\n",
    "df[[\"author\", \"title\", \"language\"]] = file_metadata\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd741ebfb26e80a",
   "metadata": {},
   "source": [
    "### Text vorbereiten und Graphen erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f17fae84e6747569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T18:12:21.000494Z",
     "start_time": "2025-06-10T18:12:20.630462Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"prepared_text\"] = df[\"file_content\"].apply(prepare_text_with_libraries)\n",
    "\n",
    "df[\"graph\"] = df[\"prepared_text\"].apply(lambda g: convert_preprocessed_tokens_to_graph(g, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff579f7c571b267",
   "metadata": {},
   "source": [
    "### Metriken berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e315e88630fd7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T18:12:35.339963Z",
     "start_time": "2025-06-10T18:12:21.010076Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basismetriken: Knotenanzahl und Kantenanzahl\n",
    "df[\"node_count\"] = df[\"graph\"].apply(lambda g: len(g.nodes))\n",
    "df[\"edge_count\"] = df[\"graph\"].apply(lambda g: len(g.edges))\n",
    "\n",
    "# Knotengrade\n",
    "df[\"degree_list\"] = df[\"graph\"].apply(lambda g: np.array([deg for node, deg in g.degree ]))\n",
    "# Alternative von ChatGPT: dataframe[\"degree_list\"] = dataframe[\"graph\"].apply(lambda g: np.fromiter(dict(g.degree).values(), dtype=float))\n",
    "df[\"average_degree\"] = df[\"degree_list\"].apply(lambda degree_list: np.mean(degree_list))\n",
    "df[\"median_degree\"] = df[\"degree_list\"].apply(lambda degree_list: np.median(degree_list))\n",
    "\n",
    "# Falls eingeschaltet: Parallele Berechnungen\n",
    "if PARALLEL:\n",
    "    distance_measures = df[\"graph\"].apply(parallel_get_distance_measures).apply(pd.Series)\n",
    "    df[[\"diameter\", \"average_distance\"]] = distance_measures\n",
    "    df[\"betweenness_list\"] = df[\"graph\"].apply(parallel_get_betweenness_list)\n",
    "\n",
    "# Ansonsten (NICHT parallel)\n",
    "else:\n",
    "    df[\"diameter\"] = df[\"graph\"].apply(lambda g: nx.diameter(g))\n",
    "    df[\"average_distance\"] = df[\"graph\"].apply(lambda g: nx.average_shortest_path_length(g))\n",
    "    df[\"betweenness_list\"] = df[\"graph\"].apply(lambda g : np.array( list(nx.betweenness_centrality(g).values()) ))\n",
    "\n",
    "# Parameter Lambda der Exponentialverteilung bestimmen\n",
    "\n",
    "df[\"lambda\"] = df[\"degree_list\"].apply(lambda d: 1 / scipy.stats.expon.fit(d)[1])\n",
    "\n",
    "# Betweenness aus Liste der Einzelwerte\n",
    "df[\"betweenness_min\"] = df[\"betweenness_list\"].apply(np.min)\n",
    "df[\"betweenness_max\"] = df[\"betweenness_list\"].apply(np.max)\n",
    "df[\"betweenness_average\"] = df[\"betweenness_list\"].apply(np.mean)\n",
    "df[\"betweenness_standard_deviation\"] = df[\"betweenness_list\"].apply(np.std)\n",
    "\n",
    "\n",
    "# Clustering\n",
    "df[\"average_clustering\"] = df[\"graph\"].apply(lambda g: nx.average_clustering(g))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6abf47b0fde5b8",
   "metadata": {},
   "source": [
    "### Speichern der Tabelle in Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b3b4be4d2fb7f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T18:13:14.543620Z",
     "start_time": "2025-06-10T18:13:14.517883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        file_name  \\\n",
      "0  Hesse_Camenzind_en_cleaned.txt   \n",
      "1                  ALL_ALL_DE.txt   \n",
      "2  Hesse_Camenzind_de_cleaned.txt   \n",
      "\n",
      "                                        file_content author      title  \\\n",
      "0  IN THE BEGINNING was the myth. God, in his sea...  Hesse  Camenzind   \n",
      "1  IN THE BEGINNING was the myth. God, in his sea...    ALL        ALL   \n",
      "2  Im Anfang war der Mythus. Wie der große Gott i...  Hesse  Camenzind   \n",
      "\n",
      "  language                                      prepared_text  \\\n",
      "0       en  [THE, BEGINNING, the, myth, God, His, Search, ...   \n",
      "1       DE  [THE, BEGINNING, the, myth, God, His, Search, ...   \n",
      "2       de  [Im, Anfang, Mythus, groß, Gott, Seele, Inder,...   \n",
      "\n",
      "                                               graph  node_count  edge_count  \\\n",
      "0  (THE, BEGINNING, the, myth, God, His, Search, ...        2022        4885   \n",
      "1  (THE, BEGINNING, the, myth, God, His, Search, ...        2130        5016   \n",
      "2  (Im, Anfang, Mythus, groß, Gott, Seele, Inder,...         116         130   \n",
      "\n",
      "                                         degree_list  ...  median_degree  \\\n",
      "0  [1, 2, 378, 2, 12, 63, 2, 57, 4, 10, 250, 2, 2...  ...            2.0   \n",
      "1  [1, 2, 378, 2, 12, 63, 2, 57, 4, 10, 250, 2, 2...  ...            2.0   \n",
      "2  [1, 2, 2, 2, 2, 6, 2, 2, 2, 6, 2, 4, 2, 2, 3, ...  ...            2.0   \n",
      "\n",
      "   diameter  average_distance  \\\n",
      "0         8          3.227776   \n",
      "1        19          3.569789   \n",
      "2        22          9.172714   \n",
      "\n",
      "                                    betweenness_list    lambda  \\\n",
      "0  [0.0, 0.0009896091044037606, 0.241419395189501...  0.260971   \n",
      "1  [0.0, 0.0009394081728511037, 0.233983539669615...  0.269552   \n",
      "2  [0.0, 0.017391304347826087, 0.0344774980930587...  0.805556   \n",
      "\n",
      "   betweenness_min  betweenness_max  betweenness_average  \\\n",
      "0              0.0         0.340486             0.001103   \n",
      "1              0.0         0.342033             0.001208   \n",
      "2              0.0         0.408327             0.071690   \n",
      "\n",
      "   betweenness_standard_deviation  average_clustering  \n",
      "0                        0.010728            0.203523  \n",
      "1                        0.010482            0.192877  \n",
      "2                        0.072903            0.010632  \n",
      "\n",
      "[3 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Nur bestimmte Spalten sollen in Datei geschrieben werden\n",
    "attributes_visible_in_file = [\n",
    "    \"author\",\n",
    "    \"title\",\n",
    "    \"language\",\n",
    "    \"node_count\",\n",
    "    \"edge_count\",\n",
    "    \"average_degree\",\n",
    "    \"median_degree\",\n",
    "    \"diameter\",\n",
    "    \"average_distance\",\n",
    "    \"betweenness_min\",\n",
    "    \"betweenness_max\",\n",
    "    \"betweenness_average\",\n",
    "    \"betweenness_standard_deviation\",\n",
    "    \"average_clustering\",\n",
    "    \"lambda\"\n",
    "]\n",
    "\n",
    "df[attributes_visible_in_file].to_csv(\"data/output/output.csv\", index=False)\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (komplNetzeEnv",
   "language": "python",
   "name": "jupyterkomplnetze"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
